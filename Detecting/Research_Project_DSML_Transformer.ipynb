{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g8UueK9WMAsA"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFdcOub5N9YE"
   },
   "outputs": [],
   "source": [
    "!pip install -q ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnvQTCzZ0CBW",
    "outputId": "8a0948e4-9748-4149-e23e-055848daad23"
   },
   "outputs": [],
   "source": [
    "!pip install -q https://github.com/amaiya/eli5/archive/refs/heads/tfkeras_0_10_1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7DvZ_8AFN6QF"
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9XDelH0qN74B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "1dbA3-V9OKPU",
    "outputId": "315f930b-7499-473f-da2d-3cf494674952"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-60731811-1707-4253-8387-4913dfc33e33\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>People in Scotland have been banned from visit...</td>\n",
       "      <td>real</td>\n",
       "      <td>peopl scotland ban visit household indoor toug...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>Eight Southern states outside Texas and Florid...</td>\n",
       "      <td>real</td>\n",
       "      <td>eight southern state outsid texa florida curre...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>#IndiaFightsCorona Nearly 74% of the total Act...</td>\n",
       "      <td>real</td>\n",
       "      <td>indiafightscorona nearli 74 total activ case n...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>Drinking hot water ou tea kills the new corona...</td>\n",
       "      <td>fake</td>\n",
       "      <td>drink hot water ou tea kill new coronaviru can...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>President Barack Obama awarded $3.7 million to...</td>\n",
       "      <td>fake</td>\n",
       "      <td>presid barack obama award 7 million wuhan inst...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>???Clearly, the Obama administration did not l...</td>\n",
       "      <td>fake</td>\n",
       "      <td>clearli obama administr leav kind game plan so...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>Florida Reopens The Infamous Hurricane Beach h...</td>\n",
       "      <td>fake</td>\n",
       "      <td>florida reopen infam hurrican beach</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>@GracieLuAnn24 @kevinfurr @PeterZeihan @alexis...</td>\n",
       "      <td>real</td>\n",
       "      <td>whole reason california switch peopl test test...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>There are 10 people with COVID-19 in our hospi...</td>\n",
       "      <td>real</td>\n",
       "      <td>10 peopl covid 19 hospit today 2 aucklandd cit...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Our daily update is published. We’ve now track...</td>\n",
       "      <td>real</td>\n",
       "      <td>daili updat publish track 22.5 million test 58...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60731811-1707-4253-8387-4913dfc33e33')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-60731811-1707-4253-8387-4913dfc33e33 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-60731811-1707-4253-8387-4913dfc33e33');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  tweet label  \\\n",
       "1211  People in Scotland have been banned from visit...  real   \n",
       "4275  Eight Southern states outside Texas and Florid...  real   \n",
       "4397  #IndiaFightsCorona Nearly 74% of the total Act...  real   \n",
       "2892  Drinking hot water ou tea kills the new corona...  fake   \n",
       "4263  President Barack Obama awarded $3.7 million to...  fake   \n",
       "8     ???Clearly, the Obama administration did not l...  fake   \n",
       "2435  Florida Reopens The Infamous Hurricane Beach h...  fake   \n",
       "6395  @GracieLuAnn24 @kevinfurr @PeterZeihan @alexis...  real   \n",
       "4816  There are 10 people with COVID-19 in our hospi...  real   \n",
       "755   Our daily update is published. We’ve now track...  real   \n",
       "\n",
       "                                          tweet_cleaned  tweet_len  \n",
       "1211  peopl scotland ban visit household indoor toug...         34  \n",
       "4275  eight southern state outsid texa florida curre...         16  \n",
       "4397  indiafightscorona nearli 74 total activ case n...         30  \n",
       "2892  drink hot water ou tea kill new coronaviru can...         14  \n",
       "4263  presid barack obama award 7 million wuhan inst...         18  \n",
       "8     clearli obama administr leav kind game plan so...         16  \n",
       "2435                florida reopen infam hurrican beach         11  \n",
       "6395  whole reason california switch peopl test test...         40  \n",
       "4816  10 peopl covid 19 hospit today 2 aucklandd cit...         44  \n",
       "755   daili updat publish track 22.5 million test 58...         34  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./drive/MyDrive/Dataset/DSML/TrainVal.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbcI7Dk-OUBr",
    "outputId": "5d94a598-d01a-4da7-e216-1c7bc81c95f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8560.00000\n",
       "mean       26.94778\n",
       "std        22.45087\n",
       "min         3.00000\n",
       "25%        15.00000\n",
       "50%        25.00000\n",
       "75%        37.00000\n",
       "90%        44.00000\n",
       "95%        47.00000\n",
       "max      1456.00000\n",
       "Name: tweet, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tweet.str.split().apply(len).describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "Jz4yvzKqOYKA",
    "outputId": "f75cc995-e715-483b-dfd9-9eb1162d7256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake', 'real']\n",
      "      fake  real\n",
      "5065   1.0   0.0\n",
      "4761   0.0   1.0\n",
      "2623   1.0   0.0\n",
      "7367   1.0   0.0\n",
      "3498   1.0   0.0\n",
      "['fake', 'real']\n",
      "      fake  real\n",
      "1214   1.0   0.0\n",
      "6002   1.0   0.0\n",
      "3262   1.0   0.0\n",
      "5198   0.0   1.0\n",
      "2164   0.0   1.0\n",
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trn, val, preproc = text.texts_from_df(\n",
    "    data,\n",
    "    text_column = \"tweet\",\n",
    "    label_columns=\"label\",\n",
    "    maxlen=60,\n",
    "    ngram_range=2,\n",
    "    random_state=41,\n",
    "    preprocess_mode=\"bert\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4__HiG3Oa1R",
    "outputId": "200975e3-87fe-4fe7-86e3-5ef8532244ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 60\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', trn , preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c08D52BhOfWr",
    "outputId": "cdeb7405-6ad8-47dc-8923-19a0d2a25e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input-Token (InputLayer)       [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " Input-Segment (InputLayer)     [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " Embedding-Token (TokenEmbeddin  [(None, 60, 768),   23440896    ['Input-Token[0][0]']            \n",
      " g)                              (30522, 768)]                                                    \n",
      "                                                                                                  \n",
      " Embedding-Segment (Embedding)  (None, 60, 768)      1536        ['Input-Segment[0][0]']          \n",
      "                                                                                                  \n",
      " Embedding-Token-Segment (Add)  (None, 60, 768)      0           ['Embedding-Token[0][0]',        \n",
      "                                                                  'Embedding-Segment[0][0]']      \n",
      "                                                                                                  \n",
      " Embedding-Position (PositionEm  (None, 60, 768)     46080       ['Embedding-Token-Segment[0][0]']\n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " Embedding-Dropout (Dropout)    (None, 60, 768)      0           ['Embedding-Position[0][0]']     \n",
      "                                                                                                  \n",
      " Embedding-Norm (LayerNormaliza  (None, 60, 768)     1536        ['Embedding-Dropout[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Embedding-Norm[0][0]']         \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Embedding-Norm[0][0]',         \n",
      " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-1-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-2-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-2-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-2-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-3-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-3-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-3-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-3-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-3-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-3-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-3-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-4-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-4-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-4-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-4-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-4-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-5-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-4-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-5-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-5-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-5-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-5-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-5-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-5-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-5-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-5-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-6-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-5-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-6-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-6-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-6-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-6-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-6-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-6-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-6-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-6-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-7-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-6-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-7-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-7-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-7-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-7-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-7-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-7-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-7-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-7-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-8-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-7-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-8-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-8-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-8-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-8-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-8-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-8-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 60, 768)     2362368     ['Encoder-8-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-9-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 60, 768)     0           ['Encoder-8-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-9-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 60, 768)     1536        ['Encoder-9-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward (FeedFor  (None, 60, 768)     4722432     ['Encoder-9-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward-Dropout   (None, 60, 768)     0           ['Encoder-9-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward-Add (Add  (None, 60, 768)     0           ['Encoder-9-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-9-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward-Norm (La  (None, 60, 768)     1536        ['Encoder-9-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 60, 768)     2362368     ['Encoder-9-FeedForward-Norm[0][0\n",
      " ion (MultiHeadAttention)                                        ]']                              \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 60, 768)     0           ['Encoder-10-MultiHeadSelfAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 60, 768)     0           ['Encoder-9-FeedForward-Norm[0][0\n",
      " ion-Add (Add)                                                   ]',                              \n",
      "                                                                  'Encoder-10-MultiHeadSelfAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 60, 768)     1536        ['Encoder-10-MultiHeadSelfAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward (FeedFo  (None, 60, 768)     4722432     ['Encoder-10-MultiHeadSelfAttenti\n",
      " rward)                                                          on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward-Dropout  (None, 60, 768)     0           ['Encoder-10-FeedForward[0][0]'] \n",
      "  (Dropout)                                                                                       \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward-Add (Ad  (None, 60, 768)     0           ['Encoder-10-MultiHeadSelfAttenti\n",
      " d)                                                              on-Norm[0][0]',                  \n",
      "                                                                  'Encoder-10-FeedForward-Dropout[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward-Norm (L  (None, 60, 768)     1536        ['Encoder-10-FeedForward-Add[0][0\n",
      " ayerNormalization)                                              ]']                              \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 60, 768)     2362368     ['Encoder-10-FeedForward-Norm[0][\n",
      " ion (MultiHeadAttention)                                        0]']                             \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 60, 768)     0           ['Encoder-11-MultiHeadSelfAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 60, 768)     0           ['Encoder-10-FeedForward-Norm[0][\n",
      " ion-Add (Add)                                                   0]',                             \n",
      "                                                                  'Encoder-11-MultiHeadSelfAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 60, 768)     1536        ['Encoder-11-MultiHeadSelfAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward (FeedFo  (None, 60, 768)     4722432     ['Encoder-11-MultiHeadSelfAttenti\n",
      " rward)                                                          on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward-Dropout  (None, 60, 768)     0           ['Encoder-11-FeedForward[0][0]'] \n",
      "  (Dropout)                                                                                       \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward-Add (Ad  (None, 60, 768)     0           ['Encoder-11-MultiHeadSelfAttenti\n",
      " d)                                                              on-Norm[0][0]',                  \n",
      "                                                                  'Encoder-11-FeedForward-Dropout[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward-Norm (L  (None, 60, 768)     1536        ['Encoder-11-FeedForward-Add[0][0\n",
      " ayerNormalization)                                              ]']                              \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 60, 768)     2362368     ['Encoder-11-FeedForward-Norm[0][\n",
      " ion (MultiHeadAttention)                                        0]']                             \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 60, 768)     0           ['Encoder-12-MultiHeadSelfAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 60, 768)     0           ['Encoder-11-FeedForward-Norm[0][\n",
      " ion-Add (Add)                                                   0]',                             \n",
      "                                                                  'Encoder-12-MultiHeadSelfAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 60, 768)     1536        ['Encoder-12-MultiHeadSelfAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward (FeedFo  (None, 60, 768)     4722432     ['Encoder-12-MultiHeadSelfAttenti\n",
      " rward)                                                          on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward-Dropout  (None, 60, 768)     0           ['Encoder-12-FeedForward[0][0]'] \n",
      "  (Dropout)                                                                                       \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward-Add (Ad  (None, 60, 768)     0           ['Encoder-12-MultiHeadSelfAttenti\n",
      " d)                                                              on-Norm[0][0]',                  \n",
      "                                                                  'Encoder-12-FeedForward-Dropout[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward-Norm (L  (None, 60, 768)     1536        ['Encoder-12-FeedForward-Add[0][0\n",
      " ayerNormalization)                                              ]']                              \n",
      "                                                                                                  \n",
      " Extract (Extract)              (None, 768)          0           ['Encoder-12-FeedForward-Norm[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " NSP-Dense (Dense)              (None, 768)          590592      ['Extract[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            1538        ['NSP-Dense[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,136,642\n",
      "Trainable params: 109,136,642\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7ue4KmbxOhD3"
   },
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, \n",
    "                             train_data=trn, \n",
    "                             val_data=val, \n",
    "                             batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZJr81ETOuGf",
    "outputId": "3d7f7114-3668-4623-eb30-f179f46e7264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/1024\n",
      "482/482 [==============================] - 125s 210ms/step - loss: 0.4744 - accuracy: 0.7687\n",
      "Epoch 2/1024\n",
      "482/482 [==============================] - 106s 219ms/step - loss: 0.3316 - accuracy: 0.8397\n",
      "Epoch 3/1024\n",
      "482/482 [==============================] - 16s 33ms/step - loss: 0.7801 - accuracy: 0.4696\n",
      "\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "bwV1l0IiOwcS",
    "outputId": "1bd0dd27-7b23-436a-bb05-1d72536ae9e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two possible suggestions for LR from plot:\n",
      "\tMin numerical gradient: 8.80E-06\n",
      "\tMin loss divided by 10: 7.55E-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6-s-jDsO20h",
    "outputId": "a63583d3-944c-4796-8359-fd1ff5343d30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJKGcg8NO5BC",
    "outputId": "eb40cff4-098a-4e9d-d78a-8457d2fbc4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 8.8e-06...\n",
      "Epoch 1/3\n",
      "482/482 [==============================] - 126s 223ms/step - loss: 0.3017 - accuracy: 0.8685 - val_loss: 0.1275 - val_accuracy: 0.9498\n",
      "Epoch 2/3\n",
      "482/482 [==============================] - 107s 221ms/step - loss: 0.1068 - accuracy: 0.9602 - val_loss: 0.0706 - val_accuracy: 0.9708\n",
      "Epoch 3/3\n",
      "482/482 [==============================] - 108s 224ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 0.0763 - val_accuracy: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f390057db10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(8.80E-06, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "f57MWeDrO92k"
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "aMtBAj2ySILm",
    "outputId": "a1afbf07-7ad0-433a-8bec-75e90b98554f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6f9c6955-9269-4ae9-913e-aa02006bc905\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>There has been a pandemic every 100 years</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>CoronaVac a vaccine that is being developed in...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>A possibility for #COVID19 patients to wean of...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>An alleged bot system on Twitter controlled by...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>Our daily update is published. We’ve now track...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>Handy Tips to Stay Productive While ‘Shelterin...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Lot of young bankers are affected by Corona Vi...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>The Business brothers of Kolar sold land for ₹...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>#CoronaVirusUpdates: 📍Total #COVID19 Cases in ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>There have been no cases of infection in Beiji...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f9c6955-9269-4ae9-913e-aa02006bc905')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6f9c6955-9269-4ae9-913e-aa02006bc905 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6f9c6955-9269-4ae9-913e-aa02006bc905');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "id                                                           \n",
       "53            There has been a pandemic every 100 years  fake\n",
       "1130  CoronaVac a vaccine that is being developed in...  fake\n",
       "2058  A possibility for #COVID19 patients to wean of...  real\n",
       "1362  An alleged bot system on Twitter controlled by...  fake\n",
       "1397  Our daily update is published. We’ve now track...  real\n",
       "1033  Handy Tips to Stay Productive While ‘Shelterin...  fake\n",
       "1004  Lot of young bankers are affected by Corona Vi...  fake\n",
       "1278  The Business brothers of Kolar sold land for ₹...  fake\n",
       "878   #CoronaVirusUpdates: 📍Total #COVID19 Cases in ...  real\n",
       "1343  There have been no cases of infection in Beiji...  fake"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./drive/MyDrive/Dataset/DSML/TestLabel.csv\", index_col=0)\n",
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icBn7VHtSjuX",
    "outputId": "2ea97746-7290-4da1-f0b8-516998fd12be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00193065, 0.99806935],\n",
       "       [0.9983583 , 0.00164168],\n",
       "       [0.9988937 , 0.00110631],\n",
       "       [0.00271901, 0.99728096],\n",
       "       [0.00229026, 0.99770975]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = predictor.predict_proba(test_data[\"tweet\"].values)\n",
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgvK_pusTtU7",
    "outputId": "21ad5c39-72c2-4c67-831b-4e6d1803cdc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5     True\n",
       "Name: label, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = test_data.label == \"real\"\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Uc0mr17zUOur"
   },
   "outputs": [],
   "source": [
    "import metrics as mmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "fMn6xHkrUc1q",
    "outputId": "205a3bc5-6573-4201-98ce-f24d47232ea3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6cd9078a-5f83-4f68-8d57-c7b07e3ce265\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Prevalence</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>1101</td>\n",
       "      <td>982</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cd9078a-5f83-4f68-8d57-c7b07e3ce265')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6cd9078a-5f83-4f68-8d57-c7b07e3ce265 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6cd9078a-5f83-4f68-8d57-c7b07e3ce265');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        TP   TN  FP  FN Accuracy Prevalence Sensitivity Specificity    PPV  \\\n",
       "                                                                             \n",
       "bert  1101  982  38  19    0.973      0.523       0.983       0.963  0.967   \n",
       "\n",
       "        NPV    AUC     F1 Threshold  \n",
       "                                     \n",
       "bert  0.981  0.996  0.975       0.5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.reshape((-1, 1))\n",
    "\n",
    "perfs = mmetrics.get_performance_metrics(y, probs[:, 1:], [\"bert\"])\n",
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDO9YI2MU7Dy",
    "outputId": "cc5a8c1f-4ceb-4c63-b0a5-9f1de5f7995d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two interesting correlations:\\n\\n1) Children tend to weather COVID-19 pretty well; they also get a ton of Vitamin D.\\n\\n2) Black people are getting slammed by COVID-19; black people also have much higher instances of Vitamin D deficiency (76% vs 40% in the general population).'\n",
      " 'A photo shows a 19-year-old vaccine for canine coronavirus that could be used to prevent the new coronavirus causing COVID-19.'\n",
      " '🇰🇼 Assistant Undersecretary for Public Health Affairs Dr Buthayna Almodaf highlighted the importance of risk communication &amp; public education in fighting #COVID19. The country increased testing capacity enabling 400000 people to be tested.'\n",
      " 'An audio file by an alleged worker at a health institution in Rio de Janeiro. She says that healthcare workers on public institutions in Rio are forced to state whether a patient has COVID-19 or not even before he sees a doctor. This was allegedly being done to artificially inflate the number of cases.'\n",
      " 'Says the Coronavirus Aid, Relief, and Economic Security Act gives members of Congress a pay increase.']\n"
     ]
    }
   ],
   "source": [
    "print(test_data[\"tweet\"].values[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-sxK8bGWbBI",
    "outputId": "fd9ec56b-4a43-4085-ac16-237fa7e04f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Two interesting correlations:\\n\\n1) Children tend to weather COVID-19 pretty well; they also get a ton of Vitamin D.\\n\\n2) Black people are getting slammed by COVID-19; black people also have much higher instances of Vitamin D deficiency (76% vs 40% in the general population).'\n",
    "len(example.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tr8qs4g9Wt1D",
    "outputId": "f089c22d-1aec-4ef7-ee59-d3abcd230da9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['real']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIjcZQ0cWzCy",
    "outputId": "cff59fab-7099-4824-ebff-cd8609bee9fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18855925, 0.81144077]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([example], return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "7KirZ8jw2HM6",
    "outputId": "2ed4285d-c917-4f9a-a7d4-b55aab227c29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=real\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.731</b>, score <b>1.000</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.244\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.244\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 91.22%); opacity: 0.82\" title=\"0.212\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.06%); opacity: 0.82\" title=\"-0.184\">interesting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.851\">correlations</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(120, 100.00%, 87.88%); opacity: 0.84\" title=\"0.336\">1</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 72.62%); opacity: 0.92\" title=\"1.077\">children</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.847\">tend</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.56%); opacity: 0.81\" title=\"0.107\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.73%); opacity: 0.86\" title=\"0.558\">weather</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.72%); opacity: 0.84\" title=\"-0.383\">covid</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 86.67%); opacity: 0.84\" title=\"-0.385\">19</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.55%); opacity: 0.84\" title=\"0.390\">pretty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.35%); opacity: 0.94\" title=\"1.266\">well</span><span style=\"opacity: 0.80\">; </span><span style=\"background-color: hsl(120, 100.00%, 96.09%); opacity: 0.81\" title=\"0.067\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.64%); opacity: 0.80\" title=\"0.015\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.89%); opacity: 0.86\" title=\"0.550\">get</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.09%); opacity: 0.93\" title=\"1.222\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.25%); opacity: 0.80\" title=\"-0.040\">ton</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.28%); opacity: 0.80\" title=\"0.006\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.07%); opacity: 0.92\" title=\"-1.109\">vitamin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.78%); opacity: 0.81\" title=\"0.130\">d</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 91.93%); opacity: 0.82\" title=\"0.188\">2</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 94.61%); opacity: 0.81\" title=\"0.106\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.43%); opacity: 0.81\" title=\"0.111\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.32%); opacity: 0.82\" title=\"-0.209\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.08%); opacity: 0.80\" title=\"-0.044\">getting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.05%); opacity: 0.84\" title=\"-0.330\">slammed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.98%); opacity: 0.83\" title=\"0.256\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.53%); opacity: 0.83\" title=\"-0.237\">covid</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 83.29%); opacity: 0.86\" title=\"-0.532\">19</span><span style=\"opacity: 0.80\">; </span><span style=\"background-color: hsl(0, 100.00%, 91.33%); opacity: 0.82\" title=\"-0.208\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.70%); opacity: 0.86\" title=\"0.514\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.10%); opacity: 0.83\" title=\"0.289\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.07%); opacity: 0.86\" title=\"0.589\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.55%); opacity: 0.83\" title=\"0.310\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.26%); opacity: 0.86\" title=\"0.580\">higher</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.30%); opacity: 0.95\" title=\"1.389\">instances</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.63%); opacity: 0.82\" title=\"0.198\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.07%); opacity: 0.92\" title=\"-1.109\">vitamin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.46%); opacity: 0.80\" title=\"0.004\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.92%); opacity: 0.83\" title=\"-0.296\">deficiency</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 96.01%); opacity: 0.81\" title=\"0.069\">76</span><span style=\"opacity: 0.80\">% </span><span style=\"background-color: hsl(120, 100.00%, 73.94%); opacity: 0.91\" title=\"1.004\">vs</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.15%); opacity: 0.82\" title=\"0.215\">40</span><span style=\"opacity: 0.80\">% </span><span style=\"background-color: hsl(120, 100.00%, 86.19%); opacity: 0.84\" title=\"0.405\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.60%); opacity: 0.87\" title=\"0.658\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.63%); opacity: 0.88\" title=\"0.756\">general</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.24%); opacity: 0.82\" title=\"-0.211\">population</span><span style=\"opacity: 0.80\">).</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.explain(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aB6-P-BsW_43",
    "outputId": "aa63a7fc-2250-4d7e-db95-bf11721800f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "id:762 | loss:5.18 | true:fake | pred:real)\n",
      "\n",
      "[CLS] in aura ##nga ##ba , co ##vid antibody testing in private lab available now . https : / / t . co / vp ##mi ##4 ##ns ##my ##v [SEP]\n",
      "----------\n",
      "id:726 | loss:4.91 | true:real | pred:fake)\n",
      "\n",
      "[CLS] we ' re going through the same grief but we were on the other side of the wall to each other when it happened . hospital # corona ##virus rules kept couple apart during mis ##carriage https : / / t . co / l ##s ##18 ##xa ##e ##8 ##8 ##y [SEP]\n",
      "----------\n",
      "id:365 | loss:4.82 | true:fake | pred:real)\n",
      "\n",
      "[CLS] rt @ ac ##mad ##ot ##go ##v : during # co ##vid ##19 false information about the virus is circulating online . you can take steps to protect yourself by : • che … [SEP]\n",
      "----------\n",
      "id:792 | loss:4.36 | true:fake | pred:real)\n",
      "\n",
      "[CLS] # co ##va ##xin , india ' s indigenous # co ##vid ##19 vaccine is developed by @ b ##harat ##bio ##tech in collaboration with @ ic ##m ##r _ ni ##v . pre ##cl ##ini ##cal studies with small and large animals successfully completed . phase 1 human clinical trial completed . phase 2 human clinical trial [SEP]\n",
      "----------\n",
      "id:242 | loss:3.05 | true:fake | pred:real)\n",
      "\n",
      "[CLS] w ##wn brings you groundbreaking report ##age on government formation , corona ##virus , br ##ex ##it & amp ; climate change . support w ##wn and get bonus content here : https : / / t . co / 25 ##ld ##ku ##az ##yu [SEP]\n",
      "----------\n",
      "id:685 | loss:3.0 | true:real | pred:fake)\n",
      "\n",
      "[CLS] a liquid mixture is being sold with claims that it is \" # co ##vid ##19 vaccine \" . this is false ! there is currently no vaccine or drug approved for # co ##vid ##19 prevention by health authorities # take ##res ##pon ##sl ##ibility only purchase & amp ; consume drugs at accredited ph ##arm ##acies [SEP]\n",
      "----------\n",
      "id:491 | loss:2.52 | true:fake | pred:real)\n",
      "\n",
      "[CLS] new fears for boris mental health as he claims co ##vid is a bio ##we ##ap ##on triggered by sound . https : / / t . co / 7 ##hl ##s ##3 ##se ##uj ##l [SEP]\n",
      "----------\n",
      "id:327 | loss:2.48 | true:fake | pred:real)\n",
      "\n",
      "[CLS] sources confirm co ##vid 19 vaccine needs at least 6 to 10 ##m for clinical trials on more than 5000 but @ ic ##m ##r choosing only 1100 + ve patients & amp ; eager to complete before august 15 , 2020 means . . . ? https : / / t . co / 7 ##x ##8 [SEP]\n",
      "----------\n",
      "id:345 | loss:2.46 | true:fake | pred:real)\n",
      "\n",
      "[CLS] # corona ##virus # breaking : corona virus finally died today in india due to shock . https : / / t . co / z ##ob ##q ##j ##lb ##dy ##y [SEP]\n",
      "----------\n",
      "id:388 | loss:2.46 | true:fake | pred:real)\n",
      "\n",
      "[CLS] multiple studies published this year show that mask - wearing on a broad scale can reduce the spread of co ##vid - 19 a fact that ' s been emphasized by the cdc and dr . anthony fa ##uc ##i . https : / / t . co / am ##j ##t ##wu ##lic ##2 [SEP]\n"
     ]
    }
   ],
   "source": [
    "learner.view_top_losses(n=10, preproc=preproc, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "QAOyArkcYcRZ"
   },
   "outputs": [],
   "source": [
    "example = \"rt @ ac ##mad ##ot ##go ##v : during # co ##vid ##19 false information about the virus is circulating online . you can take steps to protect yourself by : • che …\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "s8_s3n9GZTZs",
    "outputId": "19f047ec-fd0d-42ff-c4e1-5d7f5fa7f651"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=real\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.469</b>, score <b>-0.124</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.498\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.621\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 80.44%); opacity: 0.87\" title=\"0.961\">rt</span><span style=\"opacity: 0.80\"> @ </span><span style=\"background-color: hsl(120, 100.00%, 86.37%); opacity: 0.84\" title=\"0.574\">ac</span><span style=\"opacity: 0.80\"> ##</span><span style=\"background-color: hsl(0, 100.00%, 83.15%); opacity: 0.86\" title=\"-0.777\">mad</span><span style=\"opacity: 0.80\"> ##</span><span style=\"background-color: hsl(120, 100.00%, 90.90%); opacity: 0.82\" title=\"0.322\">ot</span><span style=\"opacity: 0.80\"> ##</span><span style=\"background-color: hsl(0, 100.00%, 97.46%); opacity: 0.80\" title=\"-0.052\">go</span><span style=\"opacity: 0.80\"> ##</span><span style=\"background-color: hsl(0, 100.00%, 97.05%); opacity: 0.80\" title=\"-0.064\">v</span><span style=\"opacity: 0.80\"> : </span><span style=\"background-color: hsl(120, 100.00%, 84.53%); opacity: 0.85\" title=\"0.688\">during</span><span style=\"opacity: 0.80\"> # </span><span style=\"background-color: hsl(120, 100.00%, 94.21%); opacity: 0.81\" title=\"0.169\">co</span><span style=\"opacity: 0.80\"> ##</span><span style=\"background-color: hsl(0, 100.00%, 85.54%); opacity: 0.85\" title=\"-0.624\">vid</span><span style=\"opacity: 0.80\"> ##</span><span style=\"background-color: hsl(0, 100.00%, 81.24%); opacity: 0.87\" title=\"-0.905\">19</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.671\">false</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.92%); opacity: 0.90\" title=\"1.372\">information</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.42%); opacity: 0.83\" title=\"0.454\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.40%); opacity: 0.90\" title=\"1.334\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.67%); opacity: 0.82\" title=\"-0.334\">virus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.58%); opacity: 0.81\" title=\"0.154\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.18%); opacity: 0.80\" title=\"0.010\">circulating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.83%); opacity: 0.84\" title=\"0.488\">online</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(0, 100.00%, 90.74%); opacity: 0.82\" title=\"-0.330\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.41%); opacity: 0.83\" title=\"0.455\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.41%); opacity: 0.87\" title=\"0.894\">take</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.67%); opacity: 0.95\" title=\"2.058\">steps</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.65%); opacity: 0.83\" title=\"0.387\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.70%); opacity: 0.86\" title=\"0.741\">protect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.99%); opacity: 0.80\" title=\"0.066\">yourself</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.08%); opacity: 0.84\" title=\"0.474\">by</span><span style=\"opacity: 0.80\"> : • </span><span style=\"background-color: hsl(0, 100.00%, 85.01%); opacity: 0.85\" title=\"-0.658\">che</span><span style=\"opacity: 0.80\"> …</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.explain(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4f28ldIaVsV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Research Project DSML Transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
